{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d5383f",
   "metadata": {},
   "source": [
    "# An AI web application for Text Summarization and Named Entity Recognition\n",
    "---\n",
    "Developer: [Olabanji Olaniyan](linkedin.com/in/olabanji-olaniyan-59a6b0198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4987d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5b2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `_` is a throwaway variable i.e we are not going to output for any operation. \n",
    "# The method it stores is just to search for variables in the local .env files\n",
    "_ = load_dotenv(find_dotenv()) # reads local .env file\n",
    "\n",
    "# load api key and endpoints\n",
    "hf_api_key = os.environ['HUGGINGFACEHUB_API_TOKEN'] # This should not be hardcoded\n",
    "sum_endpoint = os.environ[\"API_URL_SUMMARIZE\"] # summarization endpoint\n",
    "ner_endpoint = os.environ[\"API_URL_NER\"] # named entity recognization endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd16564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples for app\n",
    "example_1 = '''Andrew Yan-Tak Ng (Chinese: 吳恩達; born April 18, 1976[2]) is a British-American computer scientist and technology entrepreneur focusing on machine learning and artificial intelligence (AI).Ng was a cofounder and head of Google Brain and was the former Chief Scientist at Baidu, building the company's Artificial Intelligence Group into a team of several thousand people.\n",
    " Ng is an adjunct professor at Stanford University (formerly associate professor and Director of its Stanford AI Lab or SAIL). Ng has also worked in the field of online education, cofounding Coursera and DeepLearning.AI. He has spearheaded many efforts to \"democratize deep learning\" teaching over 8 million students through his online courses. Ng is renowned globally in computer science, \n",
    " recognized in Time magazine's 100 Most Influential People in 2012 and Fast Company's Most Creative People in 2014. His influence extends to being named in the Time100 AI Most Influential People in 2023. In 2018, he launched and currently heads the AI Fund, initially a $175-million investment fund for backing artificial intelligence startups. He has founded Landing AI, which provides AI-powe\n",
    " red SaaS products. On April 11, 2024, Amazon announced the appointment of Ng to its board of directors.\n",
    "'''\n",
    "example_2 = \"\"\"Lionel Andrés \"Leo\" Messi; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon\n",
    " d'Or awards and eight times being named the world's best player by FIFA. He is the most decorated player in the history of professional football having won 45 team trophies, including twelve Big Five league titles, four UEFA Champions Leagues, two Copa Américas, and one FIFA World Cup. Messi holds the records for most European Golden Shoes (6), most goals in a calendar year (91), most goals for\n",
    "   a single club (672, with Barcelona), most goals (474), hat-tricks (36) and assists (192) in La Liga, most assists (18) and goal contributions (32) in the Copa América, most goal contributions (21) in the World Cup, most international appearances (191) and international goals (112) by a South American male, and the second-most in the latter category outright. A prolific goalscorer and creative playmaker,\n",
    "     Messi has scored over 850 senior career goals and has provided over 380 assists for club and country\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to get a response from our endpoint. The default is summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=sum_endpoint): \n",
    "    \"\"\"\n",
    "    This function sends a POST request to a Hugging Face Inference API endpoint and returns the model's output.\n",
    "\n",
    "    Args:\n",
    "        inputs (str): The input text to be processed by the model (e.g., for summarization, translation, etc.)\n",
    "        \n",
    "        parameters (dict, optional): Additional generation parameters for the model, such as: ### Although it was not used in this program ###\n",
    "            - max_length (int): Maximum length of the generated text.\n",
    "            - min_length (int): Minimum length of the generated text.\n",
    "            - do_sample (bool): Whether or not to use sampling; use greedy decoding otherwise.\n",
    "\n",
    "        ENDPOINT_URL (str, optional):The URL of the Hugging Face model API endpoint. Defaults to `sum_endpoint`.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary parsed from the JSON response of the API. This is our selected model's output.\n",
    "        For example: if our `ENDPOINT_URL` is a summarization endpoint then the output is:\n",
    "        summarization [{summary_text: \"The summary of your text\"}]\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2cd4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for named entity recognition\n",
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        # entity_group\n",
    "        if merged_tokens and token['entity_group'].startswith('I-') and merged_tokens[-1]['entity_group'].endswith(token['entity_group'][2:]):\n",
    "            # If current token continues the entity of the last one, merge them\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            # Otherwise, add the token to the list\n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=ner_endpoint)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "\n",
    "## Now to combine named entity recognition and summarization\n",
    "def summarize_ner(text): # I implemented the validation step here because the model behaves weirdly for text of smaller words\n",
    "    \"\"\"\n",
    "    This function receives a text. It ensures the text is greater than 100 in length then passes our summarization and ner functions.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text.\n",
    "\n",
    "    Returns:\n",
    "        str: Summarized text with named entity group.\n",
    "    \"\"\"\n",
    "    word_count = len(text.split())\n",
    "    if word_count <100:\n",
    "        return {\n",
    "        \"text\": \"⚠️ Please enter at least 100 words to use the summarizer.\",\n",
    "        \"entities\": []\n",
    "    }\n",
    "    else:\n",
    "        summarized = get_completion(text)\n",
    "        # remember I don't have to define a summarization function because the default mode is summarization\n",
    "        summarized = summarized[0]['summary_text']\n",
    "        # let's perform ner on the summarized text\n",
    "        output = ner(summarized)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=ner_endpoint)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b37614f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7910\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7910/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\banji\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\banji\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\banji\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2157, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\banji\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1941, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\banji\\anaconda3\\Lib\\site-packages\\gradio\\components\\highlighted_text.py\", line 196, in postprocess\n",
      "    HighlightedToken(token=o[0], class_or_confidence=o[1])\n",
      "                                                     ~^^^\n",
      "IndexError: string index out of range\n"
     ]
    }
   ],
   "source": [
    "demo = gr.Interface(fn=summarize_ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to Summarize and find entities\",\n",
    "                                        lines=10,\n",
    "                                        placeholder= \"Enter or Paste Text here\"\n",
    "                                        )],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\",\n",
    "                                                show_legend=True,\n",
    "                                                color_map={\"PER\": \"#ff9aa2\", \"ORG\": \"#ffdac1\", \"LOC\": \"#e2f0cb\", 'MISC': \"#b5ead7\"}\n",
    "        \n",
    "                                                )],\n",
    "                    title=\"AI Text Summarizer\",\n",
    "                    description= \"\"\"<div class=\"header-text\">\n",
    "                    <h3>Generate concise summaries and highlight key entities</h3>\n",
    "                    <a href=\"https://banjiola.github.io/Olabanji-Olaniyan/\" \n",
    "                    target=\"_blank\">Olabaji Olaniyan</a>\n",
    "                    <p>This tool helps you generate quick summaries from long-form text and highlights named entities such as <mark>people</mark>, <mark>organisations</mark>, and <mark>locations</mark>. The following models were used: the <code>bart-large-cnn</code> model for text summarisation and the <code>dslim/bert-base-NER</code> model for named entity recognition.This web application is an implementation of Text Summarization and Named Entity Recognition.</p></div>\n",
    "                    \n",
    "                     <p><b><i>Click the example below to see it in action or paste your text.</b></i></p>\n",
    "                    \"\"\",\n",
    "                    flagging_mode=\"never\",\n",
    "                    examples= [example_1, example_2],    \n",
    "                    theme= 'soft',\n",
    "                    article=\"\"\"<p style='text-align: center'><i>Developed by <a href=\"https://banjiola.github.io/Olabanji-Olaniyan/\" \n",
    "                    target=\"_blank\">Olabaji Olaniyan</a> © 2025</i></p>\"\"\"\n",
    "                    )\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ed5860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7898\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37e065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ee2a1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.51.3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
